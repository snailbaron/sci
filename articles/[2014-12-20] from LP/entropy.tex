\documentclass[12pt,russian]{article}
%\documentstyle{article}
\usepackage{amsmath,amssymb,latexsym}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[T2A]{fontenc}
%\setlength{\topmargin}{15mm} \setlength{\headheight}{0pt}
%\setlength{\headsep}{0pt} \setlength{\topskip}{0pt}


\topmargin=13mm           % веpхнее поле свеpх одного дюйма (до колонтитула)
\textwidth=160mm           % шиpина текста
\oddsidemargin=0.6cm % отступ от левого однодюймового поля
\textheight=235mm % высота текста, pассчитываемая так:
\headsep=0mm % pасстояние от колонтитула (хоть и пустого) до текста
\hoffset=0mm % сдвиг всей стpаницы впpаво
\voffset=-10mm % сдвиг всей стpаницы вниз


\begin{document}

\setcounter{page}{81}


\begin{center}
{ \bf 4.
Нижняя оценка стоимости кодирования и асимптотически оптимальное кодирование.
Докритический случай}
\end{center}

{\sloppy

\vspace*{3mm}

\medskip


Под энтропией стохастического языка ${\cal L}$ будем понимать величину
$$
H({\cal L})=-\lim_{N \rightarrow \infty} \sum_{\alpha \in L, \left|\alpha\right|\le N} p(\alpha) \log p(\alpha).
$$
Если энтропия конечна, будем применять запись $H({\cal L})=-\sum_{\alpha \in L} p(\alpha) \log p(\alpha).$

Пусть ${\cal L}=(L,P)$ - стохастический КС-язык с однозначным выводом, т.е. язык, в котором каждое слово имеет единственное дерево вывода.
Кодированием языка ${\cal L}$ будем называть инъективное отображение

$f:  L \rightarrow \{ 0,1 \}^+.$

Через $L^t$ обозначим множество таких слов из $L,$ что дерево вывода каждого слова
имеет высоту $t.$ Для $\alpha \in L^t$ через $p_t(\alpha)$
обозначим условную вероятность появления слова $\alpha,$ т.е.
$p_t(\alpha)=\frac{p(\alpha)}{P(L^t)}.$
В силу однозначности вывода $P(L^t)=P(D^t).$

{\it Стоимостью кодирования} $f$ назовем величину
$$
C({\cal L},f)= \lim_{t \rightarrow \infty}
 \frac {\sum_{ \alpha \in L^t} p_t(\alpha) \cdot
 |f(\alpha)|}
 {\sum_{ \alpha \in L^t} p_t(\alpha) \cdot | \alpha|}  \eqno (1)
$$
(здесь $|x|$ -длина последовательности $x$).

Корректность определения $C({\cal L},f)$ нуждается в обосновании,
так как предел может не существовать.

Величина $C({\cal L},f)$ характеризует число двоичных разрядов,
приходящихся на кодирование одного символа слова языка.

Через $F({\cal L})$ обозначим класс всех
инъективных отображений из $L$ в $ \{ 0,1 \}^+,$ для которых
существует $C({\cal L},f).$

{\it Стоимостью оптимального кодирования} языка ${\cal L}$ назовем величину
$$
C_0({\cal L})= \inf_{f \in F({\cal L})} C({\cal L},f).
$$

Предварительно получим асимптотическую формулу для энтропии множества слов ${\cal L}^t.$ По определению имеем 
$$
H({\cal L}^t)=-\sum_{\alpha \in L^t} p_t(\alpha) \log p_t(\alpha).
$$
Следовательно, 
$$
H({\cal L}^t)=-\sum_{\alpha \in L^t} p_t(\alpha)\left( \log p(\alpha)-\log P({\cal L}^t)\right)=
$$
$$
\frac{1}{P({\cal L}^t)}\cdot \left( -\sum_{\alpha \in L^t} p(\alpha) \log p(\alpha) \right)+\log P({\cal L}^t).
$$

Для слова $\alpha$ обозначим через $q_{ij}(\alpha)$ число применений правила $r_{ij}$ при его выводе. Вероятность слова $\alpha$ равна
$p(\alpha)=\prod_{i=1}^k \prod_{j=1}^{n_i} (p_{ij})^{q_{ij}}.$ Следовательно, $\log p(\alpha)= \sum_{i=1}^k \sum_{j=1}^{n_i} q_{ij}(\alpha) \log p_{ij}.$ Поэтому 
$$
H({\cal L}^t) = \frac{1}{P({\cal L}^t)} \cdot \left( -\sum_{\alpha \in L^t} p(\alpha) \cdot \sum_{i=1}^k \sum_{j=1}^{n_i} q_{ij}(\alpha) \log p_{ij} \right)+ \log P({\cal L}^t)=
$$
$$
\frac{1}{P({\cal L}^t)} \cdot \left( - \sum_{i=1}^k \sum_{j=1}^{n_i} \log p_{ij} \cdot \sum_{\alpha \in L^t} p(\alpha) q_{ij}(\alpha)  \right)+ 
\log P({\cal L}^t).
$$
Очевидно, что $\sum_{\alpha \in L^t} p(\alpha) q_{ij}(\alpha) = {P({\cal L}^t)}\cdot M(S_{ij}(t)).$
Используя теорему 4, выражение для энтропии можно переписать в виде
$$
H({\cal L}^t) = -t\cdot (1+o(1))\sum_{i=1}^k \sum_{j=1}^{n_i} w_{ij}\log p_{ij} + 
\log P({\cal L}^t).
$$
Ввиду однозначности вывода имеем $\log P({\cal L}^t)=\log P(D^t)=t \log r+O(\log t).$ Поэтому 
$$
H({\cal L}^t) =t \cdot \left( \log r - \sum_{j=1}^{n_i} w_{ij}\log p_{ij}\right)+o(t).
$$
Полученный результат сформулируем в виде следующей теоремы.

\medskip

{\bf Теорема 5.}
{\em
Пусть ${\cal L}^t$ - множество слов с деревьями вывода высоты $t$ из стохастического КС-языка, порожденного разложимой КС-гра\-м\-ма\-ти\-кой
с однозначным выводом, для которой перронов корень $r$ матрицы первых моментов меньше 1. Тогда
$$
H({\cal L}^t) =t \cdot \left( \log r - \sum_{j=1}^{n_i} w_{ij}\log p_{ij}\right)+o(t),
$$
где $w_{ij}$ определяются теоремой 4.
}

Таким образом, энтропия $H({\cal L}^t)$ линейно зависит от высоты $t$ дерева вывода, как и в неразложимом случае.

\medskip

Используя энтропию, оценим стоимость оптимального кодирования $C_0({\cal L}).$
Обозначим через $f^*$ кодирование множества слов ${\cal L}^t,$ минимизирующее величину 
$$
M_t(f)=\sum_{\alpha \in L^t} p_t(\alpha)\cdot \left|f(\alpha)\right|.
$$
Очевидно, что для любого кодирования $f \in F(L)$ верно неравенство $M_t(f) \ge M_t(f^*).$ Оценим  $M^*({\cal L}^t)=M_t(f^*),$ используя следующую теорему, доказанную в [Борисов].

\medskip

{\bf Теорема 6.}
{\em Пусть ${\cal L}_k$ -- последовательность стохастических языков, для которой $H({\cal L}_k) \rightarrow \infty$ при $k \rightarrow \infty.$ Тогда 
$$
\lim_{k \rightarrow \infty} \frac{M^*({\cal L}_k)}{H({\cal L}_k)}=1.
$$ 
}
\medskip

Поскольку  $H({\cal L}^t \rightarrow \infty$ при $t \rightarrow \infty,$ из теоремы 6 следует, что $M_t(f^*)/H({\cal L}^t \rightarrow 1$ при $t \rightarrow \infty.$ 

Найдем величину $\sum_{ \alpha \in L^t} p_t(\alpha) \cdot | \alpha|.$ Пусть правило $r_{ij}$ содержит в правой части $l_{ij}$ терминальных символов. Очевидно, что $\left|\alpha\right|=\sum_{ij} q_{ij}(\alpha l_{ij}.$ Поэтому 
$$
\sum_{ \alpha \in L^t} p_t(\alpha) \cdot | \alpha|=\sum_{ij} l_{ij} M(S_{ij}(t))= t\cdot \sum_{ij} l_{ij} w_{ij} +o(t).
$$
Следовательно, справедлива

\medskip

{\bf Теорема 7.} 
{\em 
Пусть ${\cal L}$ - стохастический КС-язык, порожденный разложимой КС-гра\-м\-ма\-ти\-кой
с однозначным выводом, для которой перронов корень $r$ матрицы первых моментов меньше 1. Тогда
стоимость любого кодирования $f \in F({\cal L})$ удовлетворяет неравенству
$$
C({\cal L},f)= \ge C_0({\cal L})= \frac {\log r-\sum_{ij} w_{ij}\log p_{ij}}{\sum_{ij} l_{ij} w_{ij}}.
$$
}

\medskip
Можно показать, что эта оценка является точной, т.е. существует кодирование $f \in F({\cal L}),$ стоимость которого сколь угодно близка к $C_0({\cal L}).$ Для этого будем использовать схему локально-префиксного кодирования из [Жильцова, Дискр. ан. 2001]. В качестве частоты применения правила $r_{ij}$ возьмем $p_{ij}'=\frac{w_{ij}}{w_i},$ где $w_i = \sum_{j} w_{ij}.$ Для каждого множества правил $R_i$ с одинаковой левой частью $A_i$ применим схему кодирования, построенную по алгоритму Шеннона. При этом правилу $r_{ij}$ будет соответствовать элементарный код длины $\left\lceil  \log p_{ij}'\right\rceil.$  

Код слова $\alpha \in {\cal L},$ имеющего левый вывод $w(\alpha)=r_{i_1 j_1} r_{i_2 j_2} \ldots r_{i_n j_n},$ получается конкатенацией кодов правил $r_{i_s j_s}.$ Такое кодирование обозначим через $f_{sh}.$
По аналогии с [Жил, Д.а. 2001] доказывается, что стоимость кодирования $f_{sh}$ стремится к $C_0({\cal L})$ при описанном в [Жил, Д.а. 2001] методе укрупнения правил грамматики.

}
\end{document}
